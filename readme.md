# AgentFlow  
**Retrievalâ€‘Augmented Intelligent Work Allocation & Dynamic AIâ€‘Talent Pairing Platform**

---

## ğŸš€â€¯What Is AgentFlow?

AgentFlow is a proofâ€‘ofâ€‘concept system that **analyzes any project brief, breaks it into atomic tasks, and decides in real time whether each task should be handled by an AI agent or a human expert**.  
It thenâ€¯feeds both parties the right context (via RAG), orchestrates their handâ€‘offs, and streams live status updates to a responsive Kanbanâ€‘style dashboard.

---

## âœ¨â€¯Key Capabilities

| Capability | How it works |
|------------|--------------|
| **Task Decomposition** | GPTâ€‘powered splitter converts raw specs into structured task objects. |
| **Intelligent Routing** | Heuristicâ€¯+â€¯ML / LLM rules decide **AI vsâ€¯human** and pick an assignee based on skills & availability. |
| **RAG for Context** | pgvectorâ€‘backed store retrieves the topâ€‘K docs; injected into prompts & human briefs. |
| **Orchestration Loop** | Async queue executes AI tasks (LLMs) or pings human workers; supports iterative reviewâ€‘refine cycles. |
| **Live Dashboard** | Reactâ€¯+â€¯Tailwind UI shows **Queued â†’ Inâ€‘Progress â†’ Done** columns with WebSocket updates. |
| **Pluggable Models** | Works with OpenAI GPTâ€‘4o, Metaâ€¯Llamaâ€‘3 (via vLLM/TGI), or any OpenAIâ€‘compatible endpoint. |

---

## âœ¨â€¯Whatâ€™s Inside
* **Backend** â€“ FastAPI, Chroma (inâ€‘memory), Ollamaâ€‘served Phiâ€‘3â€¯mini (3.8â€¯B) for chat + embeddings.
* **Frontend** â€“ React + Vite + Tailwind Kanban board (live WebSocket updates).
* **No paid cloud** â€“ Runs on local CPU, free RunPod CPU pod, or a Huggingâ€¯Face Space.

---

## ğŸ›ï¸Â Layered Architecture Overview

The AgentFlow stack is organized into **four clear layers**, each with focused responsibilities.

#### 1.Â UIÂ Layer
| Component | Responsibility |
|-----------|----------------|
| **KanbanÂ DashboardÂ (React)** | Live board showing task cards moving through *Queued â†’ Inâ€‘Progress â†’ Done*. |
| **TaskÂ ManagementÂ UI** | Edit, reâ€‘assign, or reâ€‘run tasks; view AI / human outputs. |
| **ProjectÂ BriefÂ Upload** | Dropâ€‘zone for PDFs / Markdown / text specs that kickâ€‘off analysis. |

---

#### 2.Â LLMÂ ServiceÂ Layer
| Component | Responsibility |
|-----------|----------------|
| **Ollama** | Local serving infrastructure exposing an **OpenAIâ€‘compatible** REST endpoint. |
| **Metaâ€¯Llamaâ€‘3â€‘8Bâ€‘Instruct** | Primary language model that powers task analysis and AI execution. |
| **OpenAI Compatibility Adapter** | Lets backend call `ChatCompletion` & `Embedding` endpoints without code changes. |

---

#### 3.Â HumanÂ Layer
| Role | Responsibility |
|------|----------------|
| **Experts** | Tackle complex, domainâ€‘specific tasks the LLM shouldnâ€™t handle. |
| **Reviewers** | Validate AI / expert work; request revisions if quality fails. |

---

#### 4.Â ServiceÂ Layer
| Microâ€‘service | Key Functions |
|---------------|---------------|
| **TaskÂ Analyzer** | â€¢ Parse project brief<br>â€¢ Decompose into atomic tasks<br>â€¢ Map task dependencies |
| **Router** | â€¢ Decide *AIÂ vsÂ Human* per task<br>â€¢ Allocate resources / match skills |
| **Orchestrator** | â€¢ Schedule tasks<br>â€¢ Manage handâ€‘offs & retries<br>â€¢ Track status for UI & logs |
| **RAGÂ System** | â€¢ Index docs in ChromaDB<br>â€¢ Retrieve topâ€‘K context<br>â€¢ Enrich prompts & human briefs |
| **APIÂ Gateway** | â€¢ **FastAPI** endpoints (REST + WebSockets)<br>â€¢ CORS middleware for the React frontâ€‘end |

---

#### 5.Â DataÂ Layer
| Store | Purpose |
|-------|---------|
| **AsyncÂ TaskÂ Queue** | Buffers tasks for the orchestrator workers. |
| **ChromaDBÂ (VectorÂ Store)** | Stores Llama embeddings for similarity search in the RAG pipeline. |
| **DocumentÂ Storage** | Holds raw project briefs, task outputs, and any supporting files. |




## ğŸ› ï¸â€¯Stack

| Layer | 	Tech | 
|------------|--------------|
| **API & WS**	| FastAPI, Uvicorn|
| **Queue / Async**	| Python asyncio (swap in Celery/Temporal) |
| **Vector Store**|	PostgresÂ + pgvector (HNSW) |
|**LLM Serving** |	 vLLM / TGI + Metaâ€¯Llama |
| **Frontâ€‘End**|	React, TailwindCSS, shadcn/ui, framerâ€‘motion |
|**DevOps**| DockerÂ Compose, dotenv| 

